<h1 id="gan-image-colorization-with-controlled-parameters">GAN Image Colorization with Controlled Parameters</h1>
<h2 id="task">Task</h2>
<p>Given a grayscale (b&amp;w) image and a set of parameters as the input, automatically generate a colorized image respecting these parameters as the output.</p>
<div class="figure">
<img src="zhang_colorization_example_cropped.jpg" />

</div>
<p>[Zhang, Isola, Efros]</p>
<h2 id="color-space">Color Space</h2>
<p>For the colorization process, the <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?Lab" alt="Lab" title="Lab" /> color space is used; One of the channels (<img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?L" alt="L" title="L" />) is the input, and this also prevents sudden jumps in both color and brightness, unlike RGB.</p>
<div class="figure">
<img src="cifar10_saturation0_17000_colorjump.png" />

</div>
<h2 id="model">Model</h2>
<h3 id="generator">Generator</h3>
<p>Symmetric with skip connections, the encoder part consisting of <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?4%20%5Ctimes%204" alt="4 \times 4" title="4 \times 4" /> convolution layers with stride <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?2" alt="2" title="2" />, each followed by batch normalization and LeakyReLU with slope <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?0.2" alt="0.2" title="0.2" />; the decoder part consisting of <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?4%20%5Ctimes%204" alt="4 \times 4" title="4 \times 4" /> transposed convolution layers with stride <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?2" alt="2" title="2" />, concatenation with the activation map of its encoder mirrored layer, followed by batch normalization and ReLU; the last layer is a <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?1%20%5Ctimes%201" alt="1 \times 1" title="1 \times 1" /> convolution with <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Ctanh" alt="\tanh" title="\tanh" /> activation function.</p>
<div class="figure">
<img src="generator.png" />

</div>
<h3 id="discriminator">Discriminator</h3>
<p>Formed by a series of <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?4%20%5Ctimes%204" alt="4 \times 4" title="4 \times 4" /> convolutional layers with stride <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?2" alt="2" title="2" />, batch normalization, and LeakyReLU with slope <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?0.2" alt="0.2" title="0.2" />. After the last layer, a convolution is applied to map a <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?1" alt="1" title="1" /> dimensional output, followed by a sigmoid function in order to return a probability value of the input's veracity.</p>
<div class="figure">
<img src="discriminator.png" />

</div>
<h3 id="changes-for-better-performance">Changes for Better Performance</h3>
<ul>
<li>Adam optimization;</li>
<li>Weight initialization as proposed by [He, Kaiming et al.];</li>
<li>Initial learning rate of <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?2%20%5Ccdot%2010%5E%7B-4%7D" alt="2 \cdot 10^{-4}" title="2 \cdot 10^{-4}" /> for both the generator and the discriminator;</li>
<li>Decay the learning rate by a factor of <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?10" alt="10" title="10" /> when the loss function starts to plateau;</li>
<li>L1-Norm in the generator's loss function (<img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Clambda%20%5Cleft%5ClVert%20G%5Cleft%28%200_z%20%5Cmid%20x%20%5Cright%29%20-%20y%20%5Cright%5CrVert_1" alt="\lambda \left\lVert G\left( 0_z \mid x \right) - y \right\rVert_1" title="\lambda \left\lVert G\left( 0_z \mid x \right) - y \right\rVert_1" />) with <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Clambda%20%3D%20100" alt="\lambda = 100" title="\lambda = 100" />;</li>
<li>Heuristic cost function proposed by [Goodfellow, Nips 2016 tutorial];</li>
<li>One sided label smoothing;</li>
<li>Batch normalization;</li>
<li>Strided convolutions instead of spatial pooling;</li>
<li>Reduced momentum;</li>
<li>LeakyReLU instead of ReLU;</li>
</ul>
<h3 id="cost-functions">Cost Functions</h3>
<p>The cost functions defined by [Nazeri, Kamyar and Ng, Eric and Ebrahimi, Mehran] are as follows:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cunderset%7B%5Ctheta_G%7D%7B%5Cmin%7D%20J%5E%7B%5Cleft%28G%5Cright%29%7D%20%5Cleft%28%5Ctheta_D%2C%20%5Ctheta_G%5Cright%29%20%3D%20%5Cunderset%7B%5Ctheta_G%7D%7B%5Cmin%7D%20-%5Cmathbb%7BE%7D_z%20%5Cleft%5B%20%5Clog%20%5Cleft%28%20D%20%5Cleft%28%200_z%20%5Cmid%20x%20%5Cright%29%20%5Cright%29%20%5Cright%5D%20%2B%20%5Clambda%20%5Cleft%5ClVert%20G%5Cleft%28%200_z%20%5Cmid%20x%20%5Cright%29%20-%20y%20%5Cright%5CrVert_1" alt="\underset{\theta_G}{\min} J^{\left(G\right)} \left(\theta_D, \theta_G\right) = \underset{\theta_G}{\min} -\mathbb{E}_z \left[ \log \left( D \left( 0_z \mid x \right) \right) \right] + \lambda \left\lVert G\left( 0_z \mid x \right) - y \right\rVert_1" title="\underset{\theta_G}{\min} J^{\left(G\right)} \left(\theta_D, \theta_G\right) = \underset{\theta_G}{\min} -\mathbb{E}_z \left[ \log \left( D \left( 0_z \mid x \right) \right) \right] + \lambda \left\lVert G\left( 0_z \mid x \right) - y \right\rVert_1" /><br /></p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cunderset%7B%5Ctheta_D%7D%7B%5Cmax%7D%20J%5E%7B%5Cleft%28D%5Cright%29%7D%20%5Cleft%28%5Ctheta_D%2C%20%5Ctheta_G%5Cright%29%20%3D%20%5Cunderset%7B%5Ctheta_D%7D%7B%5Cmax%7D%20%5Cleft%28%20%5Cmathbb%7BE%7D_y%5Cleft%5B%20%5Clog%20%5Cleft%28D%5Cleft%28y%20%5Cmid%20x%5Cright%29%5Cright%29%20%5Cright%5D%20%2B%20%5Cmathbb%7BE%7D_z%5Cleft%5B%20%5Clog%20%5Cleft%28%201%20-%20D%5Cleft%28G%5Cleft%28%200_z%20%5Cmid%20x%20%5Cright%29%20%5Cmid%20x%20%5Cright%29%20%5Cright%29%20%5Cright%5D%20%5Cright%29" alt="\underset{\theta_D}{\max} J^{\left(D\right)} \left(\theta_D, \theta_G\right) = \underset{\theta_D}{\max} \left( \mathbb{E}_y\left[ \log \left(D\left(y \mid x\right)\right) \right] + \mathbb{E}_z\left[ \log \left( 1 - D\left(G\left( 0_z \mid x \right) \mid x \right) \right) \right] \right)" title="\underset{\theta_D}{\max} J^{\left(D\right)} \left(\theta_D, \theta_G\right) = \underset{\theta_D}{\max} \left( \mathbb{E}_y\left[ \log \left(D\left(y \mid x\right)\right) \right] + \mathbb{E}_z\left[ \log \left( 1 - D\left(G\left( 0_z \mid x \right) \mid x \right) \right) \right] \right)" /><br /></p>
<p>In order to introduce controls over parameters, new terms are introduced as follows:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Ccdots%20%2B%20%5Clambda_S%20%5Cleft%5Clvert%20%5Coverline%7BG%5Cleft%28%200_z%20%5Cmid%20x%20%5Cright%29_S%7D%20-%20%5Csigma_S%20%5Cright%5Crvert" alt="\cdots + \lambda_S \left\lvert \overline{G\left( 0_z \mid x \right)_S} - \sigma_S \right\rvert" title="\cdots + \lambda_S \left\lvert \overline{G\left( 0_z \mid x \right)_S} - \sigma_S \right\rvert" /><br /> <br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Ccdots%20%2B%20%5Clambda_H%20%5Cleft%5Clvert%20%5Coverline%7BG%5Cleft%28%200_z%20%5Cmid%20x%20%5Cright%29_H%7D%20-%20%5Csigma_H%20%5Cright%5Crvert" alt="\cdots + \lambda_H \left\lvert \overline{G\left( 0_z \mid x \right)_H} - \sigma_H \right\rvert" title="\cdots + \lambda_H \left\lvert \overline{G\left( 0_z \mid x \right)_H} - \sigma_H \right\rvert" /><br /> <br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Ccdots%20%2B%20%5Clambda_R%20%5Cleft%5Clvert%20%5Coverline%7BG%5Cleft%28%200_z%20%5Cmid%20x%20%5Cright%29_R%7D%20-%20%5Csigma_R%20%5Cright%5Crvert" alt="\cdots + \lambda_R \left\lvert \overline{G\left( 0_z \mid x \right)_R} - \sigma_R \right\rvert" title="\cdots + \lambda_R \left\lvert \overline{G\left( 0_z \mid x \right)_R} - \sigma_R \right\rvert" /><br /> <br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Ccdots%20%2B%20%5Clambda_G%20%5Cleft%5Clvert%20%5Coverline%7BG%5Cleft%28%200_z%20%5Cmid%20x%20%5Cright%29_G%7D%20-%20%5Csigma_G%20%5Cright%5Crvert" alt="\cdots + \lambda_G \left\lvert \overline{G\left( 0_z \mid x \right)_G} - \sigma_G \right\rvert" title="\cdots + \lambda_G \left\lvert \overline{G\left( 0_z \mid x \right)_G} - \sigma_G \right\rvert" /><br /> <br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Ccdots%20%2B%20%5Clambda_B%20%5Cleft%5Clvert%20%5Coverline%7BG%5Cleft%28%200_z%20%5Cmid%20x%20%5Cright%29_B%7D%20-%20%5Csigma_B%20%5Cright%5Crvert" alt="\cdots + \lambda_B \left\lvert \overline{G\left( 0_z \mid x \right)_B} - \sigma_B \right\rvert" title="\cdots + \lambda_B \left\lvert \overline{G\left( 0_z \mid x \right)_B} - \sigma_B \right\rvert" /><br /> <br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cvdots" alt="\vdots" title="\vdots" /><br /></p>
<h2 id="environment-setup">Environment Setup</h2>
<ul>
<li>Google Colab</li>
<li>Tesla K80 GPU</li>
<li>12 hours of usage before timeout</li>
<li>Ability to run multiple instances at once (max. 10);</li>
<li>Quirkiness;</li>
<li>Tensorflow</li>
</ul>
<h2 id="results">Results</h2>
<ul>
<li>Trained using CIFAR-10 dataset; Places365 was too large to fit Colab's storage and even when reduced did not train even one epoch before timeout;</li>
<li>Time to train the model with different parameters changed a lot; training with approx. 200 epochs takes aroudn 6 days;</li>
</ul>
<h3 id="previous-results">Previous Results</h3>
<p>From [Nazeri, Kaymar and Ng, Eric and Ebrahimi, Mehran]</p>
<p>Grayscale / Original / U-Net / GAN</p>
<div class="figure">
<img src="nazeri_cifar10_cropped.png" />

</div>
<h3 id="sigma_s-1"><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Csigma_S%20%3D%201" alt="\sigma_S = 1" title="\sigma_S = 1" /></h3>
<p>(70000 steps = 179 epochs)</p>
<div class="figure">
<img src="cifar10_saturation1_70000.png" />

</div>
<h3 id="sigma_s-0.75"><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Csigma_S%20%3D%200.75" alt="\sigma_S = 0.75" title="\sigma_S = 0.75" /></h3>
<p>(83000 steps = 212 epochs)</p>
<div class="figure">
<img src="cifar10_saturation0.75_83000.png" />

</div>
<h3 id="sigma_s-0.5"><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Csigma_S%20%3D%200.5" alt="\sigma_S = 0.5" title="\sigma_S = 0.5" /></h3>
<p>(82000 steps = 209 epochs)</p>
<div class="figure">
<img src="cifar10_saturation0.5_82000.png" />

</div>
<h3 id="sigma_s-0.25"><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Csigma_S%20%3D%200.25" alt="\sigma_S = 0.25" title="\sigma_S = 0.25" /></h3>
<p>(85000 steps = 217 epochs)</p>
<div class="figure">
<img src="cifar10_saturation0.25_85000.png" />

</div>
<h3 id="sigma_s-0"><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Csigma_S%20%3D%200" alt="\sigma_S = 0" title="\sigma_S = 0" /></h3>
<p>(81000 steps = 207 epochs)</p>
<div class="figure">
<img src="cifar10_saturation0_81000.png" />

</div>
<h3 id="sigma_h-0"><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Csigma_H%20%3D%200" alt="\sigma_H = 0" title="\sigma_H = 0" /></h3>
<p>(78000 steps = 199 epochs)</p>
<div class="figure">
<img src="cifar10_hue0_78000.png" />

</div>
<h3 id="sigma_h-0.25"><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Csigma_H%20%3D%200.25" alt="\sigma_H = 0.25" title="\sigma_H = 0.25" /></h3>
<p>(78000 steps = 199 epochs)</p>
<div class="figure">
<img src="cifar10_hue0.25_78000.png" />

</div>
<h3 id="sigma_h-0.6"><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Csigma_H%20%3D%200.6" alt="\sigma_H = 0.6" title="\sigma_H = 0.6" /></h3>
<p>(78000 steps = 199 epochs)</p>
<div class="figure">
<img src="cifar10_hue0.6_78000.png" />

</div>
<h3 id="sigma_h-0.85"><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Csigma_H%20%3D%200.85" alt="\sigma_H = 0.85" title="\sigma_H = 0.85" /></h3>
<p>(78000 steps = 199 epochs)</p>
<div class="figure">
<img src="cifar10_hue0.85_78000.png" />

</div>
<h3 id="sigma_s-0.75-sigma_h-0.6"><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Csigma_S%20%3D%200.75%2C%20%5Csigma_H%20%3D%200.6" alt="\sigma_S = 0.75, \sigma_H = 0.6" title="\sigma_S = 0.75, \sigma_H = 0.6" /></h3>
<p>(73000 steps = 186 epochs)</p>
<div class="figure">
<img src="cifar10_saturation0.75_hue0.6_73000.png" />

</div>
<h2 id="further-work">Further Work</h2>
<ul>
<li>Experiment further with the added loss function terms (on the discriminator, on the generator, on both, etc.)</li>
<li>Experiment with adding weights to the added terms on the loss function (the results were generated with <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Clambda_%5Cast%20%3D%201" alt="\lambda_\ast = 1" title="\lambda_\ast = 1" />);</li>
<li>Change the L1-Norm in the generator's loss function, so that it also considers the parameters;</li>
<li>Change the dataset or only a few of its images to fit the given parameters;</li>
<li>Train the network on other datasets (CelebA, CIFAR-100, Places365, LSUN, etc.);</li>
</ul>
